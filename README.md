# Agent Voice Response - OpenAI Speech-to-Speech Integration

[![Discord](https://img.shields.io/discord/1347239846632226998?label=Discord&logo=discord)](https://discord.gg/DFTU69Hg74)
[![GitHub Repo stars](https://img.shields.io/github/stars/cierrateam/avr-sts-openai?style=social)](https://github.com/cierrateam/avr-sts-openai)
[![Docker Pulls](https://img.shields.io/docker/pulls/cierrateam/avr-sts-openai?label=Docker%20Pulls&logo=docker)](https://hub.docker.com/r/cierrateam/avr-sts-openai)
[![Ko-fi](https://img.shields.io/badge/Support%20us%20on-Ko--fi-ff5e5b.svg)](https://ko-fi.com/agentvoiceresponse)

This repository showcases the integration between **Agent Voice Response** and **OpenAI's Real-time Speech-to-Speech API**. The application leverages OpenAI's powerful language model to process audio input from users, providing intelligent, context-aware responses in real-time audio format.

## Prerequisites

To set up and run this project, you will need:

1. **Node.js** and **npm** installed
2. An **OpenAI API key** with access to the real-time API
3. **WebSocket** support in your environment

## Setup

### 1. Clone the Repository

```bash
git clone https://github.com/cierrateam/avr-sts-openai.git
cd avr-sts-openai
```

### 2. Install Dependencies

```bash
npm install
```

### 3. Configure Environment Variables

Create a `.env` file in the root of the project to store your API keys and configuration. You will need to add the following variables:

```bash
OPENAI_API_KEY=your_openai_api_key
PORT=6030
OPENAI_MODEL=gpt-4o-realtime-preview  # Optional, defaults to gpt-4o-realtime-preview

# Choose one of the following instruction loading methods:
OPENAI_INSTRUCTIONS="You are a helpful assistant that can answer questions and help with tasks."  # Method 1: Direct variable
#OPENAI_URL_INSTRUCTIONS="https://your-api.com/instructions"  # Method 2: Web service
#OPENAI_FILE_INSTRUCTIONS="./instructions.txt"  # Method 3: Local file

OPENAI_TEMPERATURE=0.8  # Optional, controls randomness (0.0-1.0), defaults to 0.8
OPENAI_MAX_TOKENS=100  # Optional, controls response length, defaults to "inf"
```

Replace `your_openai_api_key` with your actual OpenAI API key.

### 4. Running the Application

Start the application by running the following command:

```bash
node index.js
```

The server will start on the port defined in the environment variable (default: 6030).

## How It Works

The **Agent Voice Response** system integrates with OpenAI's Real-time Speech-to-Speech API to provide intelligent audio-based responses to user queries. The server receives audio input from users, forwards it to OpenAI's API, and then returns the model's response as audio in real-time using WebSocket communication.

### Key Components

- **Express.js Server**: Handles incoming audio streams from clients
- **WebSocket Communication**: Manages real-time communication with OpenAI's API
- **Audio Processing**: Handles audio format conversion between 8kHz and 24kHz
- **Real-time Streaming**: Processes and streams audio data in real-time

### Audio Processing

The application includes two main audio processing functions:

1. **Upsampling (8kHz to 24kHz)**:
   - Converts client audio from 8kHz to 24kHz using linear interpolation
   - Required for OpenAI's API which expects 24kHz input

2. **Downsampling (24kHz to 8kHz)**:
   - Converts OpenAI's 24kHz output back to 8kHz
   - Ensures compatibility with client audio systems

## API Endpoints

### POST `/speech-to-speech-stream`

This endpoint accepts an audio stream and returns a streamed audio response generated by OpenAI.

**Request:**
- Content-Type: audio/x-raw
- Format: 16-bit PCM at 8kHz
- Method: POST

**Response:**
- Content-Type: text/event-stream
- Format: 16-bit PCM at 8kHz
- Streamed audio data in real-time

## Customizing the Application

### Environment Variables

You can customize the application behavior using the following environment variables:

- `OPENAI_API_KEY`: Your OpenAI API key (required)
- `PORT`: The port on which the server will listen (default: 6030)
- `OPENAI_MODEL`: The OpenAI model to use (default: gpt-4o-realtime-preview)
- `OPENAI_INSTRUCTIONS`: Custom instructions for the AI (optional)
- `OPENAI_URL_INSTRUCTIONS`: URL to fetch instructions from a web service (optional)
- `OPENAI_FILE_INSTRUCTIONS`: Path to a local file containing instructions (optional)
- `OPENAI_TEMPERATURE`: Controls randomness in responses (0.0-1.0, default: 0.8)
- `OPENAI_MAX_TOKENS`: Controls the maximum length of the response (default: "inf")

### Instruction Loading Methods

The application supports three different methods for loading AI instructions, with a specific priority order:

#### 1. Environment Variable (Highest Priority)
Set the `OPENAI_INSTRUCTIONS` environment variable with your custom instructions:

```bash
OPENAI_INSTRUCTIONS="You are a specialized customer service agent for a tech company. Always be polite and helpful."
```

#### 2. Web Service (Medium Priority)
If no environment variable is set, the application can fetch instructions from a web service using the `OPENAI_URL_INSTRUCTIONS` environment variable:

```bash
OPENAI_URL_INSTRUCTIONS="https://your-api.com/instructions"
```

The web service should return a JSON response with a `system` field containing the instructions:
```json
{
  "system": "You are a helpful assistant that provides technical support."
}
```

The application will include the session UUID in the request headers as `X-AVR-UUID` for personalized instructions.

#### 3. File (Lowest Priority)
If neither environment variable nor web service is configured, the application can load instructions from a local file using the `OPENAI_FILE_INSTRUCTIONS` environment variable:

```bash
OPENAI_FILE_INSTRUCTIONS="./instructions.txt"
```

The file should contain plain text instructions that will be used as the system prompt.

#### Priority Order
The application checks for instructions in the following order:
1. **Environment Variable** (`OPENAI_INSTRUCTIONS`) - Used if set
2. **Web Service** (`OPENAI_URL_INSTRUCTIONS`) - Used if environment variable is not set
3. **File** (`OPENAI_FILE_INSTRUCTIONS`) - Used if neither environment variable nor web service is configured
4. **Default Instructions** - Fallback if none of the above are available

This priority system allows for flexible configuration where you can override instructions at different levels depending on your deployment needs.

## Error Handling

The application includes comprehensive error handling for:
- WebSocket connection issues
- Audio processing errors
- OpenAI API errors
- Stream processing errors

All errors are logged to the console and appropriate error messages are returned to the client.

## Support & Community

*   **GitHub:** [https://github.com/agentvoiceresponse](https://github.com/agentvoiceresponse) - Report issues, contribute code.
*   **Discord:** [https://discord.gg/DFTU69Hg74](https://discord.gg/DFTU69Hg74) - Join the community discussion.
*   **Docker Hub:** [https://hub.docker.com/u/agentvoiceresponse](https://hub.docker.com/u/agentvoiceresponse) - Find Docker images.
*   **NPM:** [https://www.npmjs.com/~agentvoiceresponse](https://www.npmjs.com/~agentvoiceresponse) - Browse our packages.
*   **Wiki:** [https://wiki.agentvoiceresponse.com/en/home](https://wiki.agentvoiceresponse.com/en/home) - Project documentation and guides.

## Support AVR

AVR is free and open-source. If you find it valuable, consider supporting its development:

<a href="https://ko-fi.com/agentvoiceresponse" target="_blank"><img src="https://ko-fi.com/img/githubbutton_sm.svg" alt="Support us on Ko-fi"></a>

## License

MIT License - see the [LICENSE](LICENSE.md) file for details.